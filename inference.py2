# inference.py  â€” Day 7 hotfix: correct MobileNetV3-Large head (1280 -> num_classes) and top-k output
from __future__ import annotations
import os
from typing import List, Tuple

import torch
import torch.nn as nn
import torch.nn.functional as F
from PIL import Image
from torchvision import transforms, models

# ---- Paths & labels ----
MODEL_PATH = os.path.join("models", "recycler_v1.pt")
FALLBACK_CLASS_NAMES = ["cardboard", "mixed", "trash"]
DISPLAY_NAME = {
    "cardboard": "Cardboard",
    "mixed": "Mixed Recyclables",
    "trash": "Trash / Non-recyclables",
}

_device = torch.device("cpu")
_model: nn.Module | None = None
_class_names: List[str] = FALLBACK_CLASS_NAMES.copy()

# Standard ImageNet preprocessing to match pretrained backbones
_transform = transforms.Compose([
    transforms.Resize((224, 224), interpolation=transforms.InterpolationMode.BILINEAR),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225]),
])

def _build_mnv3(num_classes: int) -> nn.Module:
    """
    Build MobileNetV3-Large and replace the LAST Linear layer correctly.
    For torchvision, classifier is typically:
      [0] Linear(960 -> 1280), [1] Hardswish, [2] Dropout, [3] Linear(1280 -> num_classes)
    We must use classifier[-1].in_features (which is 1280), NOT classifier[0].in_features.
    """
    model = models.mobilenet_v3_large(weights=models.MobileNet_V3_Large_Weights.DEFAULT)
    in_feats_last = model.classifier[-1].in_features  # 1280
    model.classifier[-1] = nn.Linear(in_feats_last, num_classes)
    model.eval()
    return model

def _build_resnet18(num_classes: int) -> nn.Module:
    model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)
    in_feats = model.fc.in_features
    model.fc = nn.Linear(in_feats, num_classes)
    model.eval()
    return model

def _build_model(num_classes: int) -> nn.Module:
    try:
        return _build_mnv3(num_classes)
    except Exception:
        return _build_resnet18(num_classes)

def _load_checkpoint(path: str):
    """
    Robustly load a checkpoint saved as:
    - full dict with 'model_state_dict' (+ optional 'class_names'), or
    - plain state_dict
    If no file exists, return a fresh randomly-initialized MobileNetV3 head.
    """
    if not os.path.exists(path):
        model = _build_model(len(FALLBACK_CLASS_NAMES))
        return model.to(_device), FALLBACK_CLASS_NAMES.copy()

    ckpt = torch.load(path, map_location=_device)
    class_names = None
    state_dict = None

    if isinstance(ckpt, dict):
        if "class_names" in ckpt and isinstance(ckpt["class_names"], (list, tuple)):
            class_names = list(ckpt["class_names"])
        if "model_state_dict" in ckpt and isinstance(ckpt["model_state_dict"], dict):
            state_dict = ckpt["model_state_dict"]
        elif all(isinstance(k, str) for k in ckpt.keys()):
            # looks like a raw state_dict
            state_dict = ckpt

    num_classes = len(class_names) if class_names else len(FALLBACK_CLASS_NAMES)
    model = _build_model(num_classes)

    if state_dict is not None:
        # Load non-strict to allow tiny name differences between backbones
        model.load_state_dict(state_dict, strict=False)

    return model.to(_device), (class_names or FALLBACK_CLASS_NAMES[:num_classes])

def _lazy_load():
    global _model, _class_names
    if _model is None:
        _model, _class_names = _load_checkpoint(MODEL_PATH)

def predict(image: Image.Image, topk: int = 3) -> List[Tuple[str, float]]:
    """
    Return top-k (label, probability) pairs sorted by prob desc.
    """
    _lazy_load()
    assert _model is not None
    img_t = _transform(image.convert("RGB")).unsqueeze(0).to(_device)
    with torch.no_grad():
        logits = _model(img_t)
        probs = F.softmax(logits, dim=1).squeeze(0).cpu()
    k = max(1, min(topk, probs.shape[0]))
    vals, idxs = torch.topk(probs, k)
    out: List[Tuple[str, float]] = []
    for v, i in zip(vals.tolist(), idxs.tolist()):
        key = _class_names[i] if i < len(_class_names) else FALLBACK_CLASS_NAMES[i]
        out.append((DISPLAY_NAME.get(key, key.title()), float(v)))
    return out
